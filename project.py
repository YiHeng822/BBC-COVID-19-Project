# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19QalczKMxjrAsSZPeQrnhLgy5GVvGkrx
"""

import streamlit as st

# Import required libraries
import pandas as pd
import matplotlib.pyplot as plt

import numpy as np
from numpy import mean
from numpy import std

import altair as alt
from functools import reduce

from sklearn import metrics
from sklearn.preprocessing import MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.feature_selection import RFE

from sklearn.cluster import KMeans 
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

import warnings
warnings.filterwarnings('ignore')
st.set_option('deprecation.showPyplotGlobalUse', False)
st.set_page_config(page_title="BBC COVID-19 Project", page_icon="ðŸ“Š", layout='centered', initial_sidebar_state='auto')

# Read dataset
cases_malaysia = pd.read_csv('data/cases_malaysia.csv')
cases_state = pd.read_csv('data/cases_state.csv')
vax_state =  pd.read_csv('data/vax_state.csv')
vax_malaysia = pd.read_csv('data/vax_malaysia.csv')
population = pd.read_csv('data/population.csv')
deaths_malaysia = pd.read_csv('data/deaths_malaysia.csv')
deaths_state = pd.read_csv('data/deaths_state.csv')

"""# Group BBC: Project

## Exploratory Data Analysis (EDA) and Data Preprocessing 

1. Checking the shapes of each data frame
"""

shapes = {
    "row":[vax_malaysia.shape[0], vax_state.shape[0], cases_malaysia.shape[0], 
           cases_state.shape[0], deaths_malaysia.shape[0], deaths_state.shape[0]],
    "columns":[vax_malaysia.shape[1], vax_state.shape[1], cases_malaysia.shape[1],
               cases_state.shape[1], deaths_malaysia.shape[1], deaths_state.shape[1]]
}
data_sets_idx = ["vax_malaysia", "vax_state", "cases_malaysia", "cases_state", "deaths_malaysia", "deaths_state"]
shape_df = pd.DataFrame(shapes, index=data_sets_idx)
st.dataframe(shape_df.sort_values(by=['row']))

"""Data Frame 1: Shapes of every data set used

2. Dealing with missing value
"""

# Counting the Nan values
n_vaxM = vax_malaysia.isnull().sum().sum()
n_vaxS = vax_state.isnull().sum().sum()
n_casM = cases_malaysia.isnull().sum().sum()
n_casS = cases_state.isnull().sum().sum()
n_deaM = deaths_malaysia.isnull().sum().sum()
n_deaS = deaths_state.isnull().sum().sum()
null = {
    "No. of missing values":[n_vaxM, n_vaxS, n_casM, n_casS, n_deaM, n_deaS]
}
null_df = pd.DataFrame(null, index=data_sets_idx)
st.dataframe(null_df)

"""Data Frame 2: Number of missing values in every data set"""

# Display rows with NaN in cases_malaysia
st.dataframe(cases_malaysia[cases_malaysia.isnull().any(axis=1)].head())

"""Data Frame 3: Portion of NaN values in _cases_malaysia_"""

# Display rows with NaN in cases_state
st.dataframe(cases_state[cases_state.isnull().any(axis=1)].head())

"""Data Frame 4: Portion of NaN values in _cases_state_

Since the columns containing NaN values are dependent variables (which is a subset of the total new cases), we decided to fill the NaN values with 0 as the main interest is the cumulative or total cases.
"""

# Fill the NaN values with 0
cases_malaysia.fillna(0, inplace=True)
cases_state.fillna(0, inplace=True)

# Display rows with NaN after filling
st.dataframe(cases_malaysia.iloc[0:5])

"""Data Frame 5: _cases_malaysia_ after filling the NaN values"""

# Display rows with NaN after filling
st.dataframe(cases_state.iloc[10176:10181])

"""Data Frame 6: _cases_state_ after filling the NaN values

3. Detecting outliers
"""

# Histogram of daily vaccine
base = alt.Chart(vax_malaysia)
hist = base.mark_bar().encode(
    x = alt.X('daily', bin=alt.BinParams(maxbins=30)),
    y = 'count()',
)
red_mean_line = base.mark_rule(color="red").encode(
    x = alt.X('mean(daily)', title="Daily vax"), size=alt.value(5)
)
blue_median_line = base.mark_rule(color="blue").encode(
    x = alt.X('median(daily)', title="Daily vax"), size=alt.value(5)
)

st.altair_chart((hist+red_mean_line+blue_median_line).properties(width=600,height=350).interactive())

"""Figure 1: Histogram of daily vaccination"""

# Histogram of daily new cases
base = alt.Chart(cases_malaysia)
hist = base.mark_bar().encode(
    x = alt.X('cases_new', bin=alt.BinParams(maxbins=30)),
    y = 'count()',
)
red_mean_line = base.mark_rule(color="red").encode(
    x = alt.X('mean(cases_new)', title="Daily cases"), size=alt.value(5)
)
blue_median_line = base.mark_rule(color="blue").encode(
    x = alt.X('median(cases_new)', title="Daily cases"), size=alt.value(5)
)

st.altair_chart((hist+red_mean_line+blue_median_line).properties(width=600,height=350).interactive())

"""Figure 2: Histogram of daily new cases"""

# Histogram of daily new deaths
base = alt.Chart(deaths_malaysia)
hist = base.mark_bar().encode(
    x = alt.X('deaths_new', bin=alt.BinParams(maxbins=30)),
    y = 'count()',
)
red_mean_line = base.mark_rule(color="red").encode(
    x = alt.X('mean(deaths_new)', title="Daily deaths"), size=alt.value(5)
)
blue_median_line = base.mark_rule(color="blue").encode(
    x = alt.X('median(deaths_new)', title="Daily deaths"), size=alt.value(5)
)
st.altair_chart((hist+red_mean_line+blue_median_line).properties(width=600,height=350).interactive())

"""Figure 3: Histogram of daily deaths

The three example histograms of the dataset (_vax_malaysia, cases_malaysia, deaths_malaysia_) show similar shapes especially for deaths and new cases. Both histograms of deaths and new cases are skewed to the right, where the mean (red) and median (blue) lines are located at the smaller values of the x-axis. This is a good sign as the lower values represent that the daily new cases and deaths are still in control. For the vaccination rate in Malaysia, the mean and median lines are located towards the center of the x-axis which indicates our vaccination process is good enough considering that the number of vaccination centers is opening gradually and maximizing the daily dose to around 600000.

For outliers wise, there are noticeable outliers located at 0-20 in the histogram of both daily cases and deaths. Let's look closer at the line graph of daily new cases.
"""

st.altair_chart(alt.Chart(cases_malaysia).mark_line().encode(
    x='date:T',
    y='cases_new:Q',
    tooltip=['monthdate(date)','cases_new']
).properties(width=600,height=350).interactive())

"""Figure 4: Line graph of daily new cases

From the graph above, it can be observed that the daily new cases in Malaysia remain at zero to hundreds for almost one year from February to October 2020, and started to raise after that. A similar trend happens in deaths in Malaysia too.
"""

st.altair_chart(alt.Chart(deaths_malaysia).mark_line().encode(
    x='date:T',
    y='deaths_new:Q',
    tooltip=['monthdate(date)','deaths_new']
).properties(width=600,height=350).interactive())

"""Figure 5: Line graph of daily new deaths

Outliers are not being removed in both data as after looking into the vaccination data of Malaysia, the records start at _24-02-2021_, which means that the data for 2020 will be ignored after joining with the vaccination data.

4. Dataset merging

For further data manipulation, _vax_malaysia, cases_malaysia, vax_state, and cases_state_ are merged based on the date and state respectively.
"""

df1 = vax_state.merge(cases_state, on=['date','state'])
df2 = vax_malaysia.merge(cases_malaysia, on='date')

# Dataframe of vax and cases on country
st.dataframe(df2.head())

"""Data Frame 7: Vaccination merged with cases Malaysia"""

# Dataframe of vax and cases on state
st.dataframe(df1.head())

"""Data Frame 8: Vaccination merged with cases state

Other than that, we computed two new values which are 'cases_cum' and 'deaths_cum' for each state where 'cases_cum' is the cumulative count of cases and 'deaths_cum' is the cumulative count of deaths.
"""

# Make new columns of 'deaths_cum' for each state
state_name = ['Johor','Pahang','Pulau Pinang','Kedah','Kelantan','Melaka',
              'Negeri Sembilan','Perak','Perlis','Sabah','Sarawak','Selangor',
              'Terengganu','W.P. Labuan','W.P. Kuala Lumpur','W.P. Putrajaya']
deaths = []
cases = []
for i in state_name:
    deaths.append(deaths_state[(deaths_state['state'] == i) & (deaths_state['date'] >= "2021-02-24")])
    cases.append(cases_state[(cases_state['state'] == i) & (cases_state['date'] >= "2021-02-24")])

for i in deaths:
    i['deaths_cum'] = i['deaths_new'].cumsum()
    i.drop(i.columns.difference(['date','state','deaths_cum']), axis=1, inplace=True)

for i in cases:
    i['cases_cum'] = i['cases_new'].cumsum()
    i.drop(i.columns.difference(['date','state','cases_cum']), axis=1, inplace=True)

deaths_cum = pd.concat(deaths)
cases_cum = pd.concat(cases)

# Drop unused columns
d_state = deaths_state.drop(deaths_state.columns.difference(['date','state','deaths_new']), axis=1)
c_state = cases_state.drop(cases_state.columns.difference(['date','state','cases_new']), axis=1)
v_state = vax_state.drop(columns=['pfizer1','pfizer2','sinovac1','sinovac2','astra1','astra2','cansino','pending'], axis=1)

# Clip all data from 2021-02-24 to 2021-10-22
data_frames = [d_state[d_state['date'] >= "2021-02-24"], c_state[c_state['date'] >= "2021-02-24"], v_state[v_state['date'] >= "2021-02-24"], deaths_cum, cases_cum]
dcv_state = reduce(lambda left,right: pd.merge(left, right, on=['date','state'], how='outer'), data_frames)

st.dataframe(dcv_state.tail())

"""Data Frame 9: Data frame with computed 'cases_cum' and 'deaths_cum'"""

alt.data_transformers.disable_max_rows()
st.altair_chart(alt.Chart(dcv_state).mark_line().encode(
    x='date:T',
    y='deaths_cum:Q',
    color='state',
    tooltip=['monthdate(date)','deaths_cum']
).properties(width=600,height=350).interactive())

"""Figure 6: Cumulative deaths for each state

In the end, the data we used will be capped from _24-02-2021_ to _22-10-2021_.

5.Data visualizations to find interesting trend

What is the trend of new cases in Malaysia in 2021 (24/2 -22/10)?

Has vaccination helped to reduce the number of daily cases in Malaysia?
"""

base = alt.Chart(df2)
line = base.mark_line().encode(
    x='date:T',
    y='cases_new:Q',
    tooltip=['monthdate(date)','cases_new']
)

overlay_1 = pd.DataFrame({
    'date': ["2021-09-06"],
    'Color': ["red"]
})
overlay_2 = pd.DataFrame({
    'date': ["2021-09-24"],
    'Color': ["green"]
})
overlay_3 = pd.DataFrame({
    'date': ["2021-10-18"],
    'Color': ["blue"]
})


rules_1 = alt.Chart(overlay_1).mark_rule(color="red").encode(
    x='date:T'
)
rules_2 = alt.Chart(overlay_2).mark_rule(color="green").encode(
    x='date:T'
)
rules_3 = alt.Chart(overlay_3).mark_rule(color="blue").encode(
    x='date:T'
)

st.altair_chart((line+ rules_1 + rules_2 + rules_3).properties(width=600, height=350).interactive())

"""Figure 7: Daily cases in Malaysia

The figure above shows the daily cases of Covid-19 in Malaysia. The red line indicates the date when 50% of Malaysians are fully vaccinated, the green line indicates 60%, and the blue line indicates 70%. From the graph above, we can tell that as the percentage of fully vaccinated Malaysian goes higher and higher, the cases have been reduced significantly. The other thing to notice is that the number of cases, when the 60-70% population is vaccinated, will not rise more than the daily cases when 50-60% population is vaccinated. This indicates that vaccination helps in reducing daily cases in Malaysia.

What is the trend of new cases in Malaysia for each state in 2021 (24/2 -22/10)?
"""

st.altair_chart(alt.Chart(df1.reset_index()).mark_line().encode(
    x='date:T',
    y='cases_new:Q',
    color = 'state',
    tooltip=['monthdate(date)','cases_new']
).properties(
    width=600,
    height=350
).properties(width=600,height=350).interactive())

"""Figure 8: Daily cases in Malaysia by state

What is the vaccination rate in Malaysia in 2021 (24/2 - 22/10)?
"""

st.altair_chart(alt.Chart(df2.reset_index()).mark_line().encode(
    x='date:T',
    y='cumul_full:Q',
    tooltip=['monthdate(date)','cumul_full']
).properties(width=600,height=350).interactive())

"""Figure 9: Vaccination rate in Malaysia

What is the vaccination rate in Malaysia for each state in 2021 (24/2 - 22/10)?
"""

st.altair_chart(alt.Chart(df1.reset_index()).mark_line().encode(
    x='date:T',
    y='daily:Q',
    color = 'state',
    tooltip=['monthdate(date)','daily']
).properties(
    width=600,
    height=350
).properties(width=600,height=350).interactive())

"""Figure 10: Vaccination rate in Malaysia by state

6.Correlation analysis on vaccination and daily new cases for Selangor state.
"""

state = []
half_pop = []
for i in range(16):
  half_pop.append(population.loc[population['state'] == state_name[i]])
  half_pop[i] = half_pop[i][half_pop[i].columns[half_pop[i].columns.isin(['state','pop'])]]
  half_pop[i]['pop'] = half_pop[i]['pop']/2 
  half_pop[i] = half_pop[i].rename(columns={'pop': 'half_pop'})
 
for i in range(16):
  state.append(df1.loc[df1['state'] == state_name[i]])
  state[i] = state[i][state[i].columns[state[i].columns.isin(['date','cases_new','cumul_full'])]]
  state[i] = state[i][state[i].cumul_full >= half_pop[i].iloc[0]['half_pop']]
  state[i] = state[i].rename(columns={'cases_new': 'Cases_New_' + state_name[i]})
  state[i] = state[i].rename(columns={'cumul_full': 'Fully_Vaccinated_' + state_name[i]})

cor_data = (state[11]
              .corr().stack()
              .reset_index()     # The stacking results in an index on the correlation values, we need the index as normal columns for Altair
              .rename(columns={0: 'correlation', 'level_0': 'variable', 'level_1': 'variable2'}))
cor_data['correlation_label'] = cor_data['correlation'].map('{:.2f}'.format)  # Round to 2 decimal

base = alt.Chart(cor_data).encode(
    x='variable2:O',
    y='variable:O'    
)

# Text layer with correlation labels
# Colors are for easier readability
text = base.mark_text().encode(
    text='correlation_label',
    color=alt.condition(
        alt.datum.correlation > 0.5, 
        alt.value('white'),
        alt.value('black')
    )
)

# The correlation heatmap itself
cor_plot = base.mark_rect().encode(
    color='correlation:Q'
).properties(
    width=600,
    height=350
)

cor_plot + text # The '+' means overlaying the text and rect layer

"""Figure 11: Correlation analysis between vaccination and daily cases

Figure 11 above shows the correlation score between vaccination and daily cases. The scores is close to -1 which means it is strong negative correlation. Hence, we can say that if the vaccination number keeps increasing, the daily cases will be keep decreasing.

## Feature Selection

For feature selection, we wish to select the top 5 features from the data below. Feature selection is carried out to extract important features or attributes for more precise model building and training. In our case, we are trying to classify or predict a state with the given features.
"""

st.dataframe(dcv_state.head())

"""Data Frame 10: Data frame with computed 'cases_cum' and 'deaths_cum'

We have chosen to use a wrapper method that utilizes a machine learning algorithm as the evaluation criteria. Recursive feature elimination (RFE) for its efficiency and simplicity. Two classification models are used for evaluation, which is Decision Tree Classifier and Logistic Regression. To evaluate their performance, accuracy is computed with cross-validation on both models.

"""
st.info("Note: The feature selection with Logistic Regression takes around 3 minutes to execute.")

#  Prepare the label and attributes
X_f = dcv_state.iloc[:, 2:]
y_f = dcv_state['state']

# # RFE with LR
# lr = LogisticRegression()
# rfe_lr = RFE(lr, n_features_to_select=5)
# fit_lr = rfe_lr.fit(X_f, y_f)
# pipeline_lr = Pipeline(steps=[('s',rfe_lr),('m',lr)])

# # evaluate model
# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# scores_lr = cross_val_score(pipeline_lr, X_f, y_f, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')
scores_lr = 0.139869
lr_features = ["daily", "cumul_partial", "cumul_full", "cumul_partial_child", "cases_cum"]
# RFE with DTC
dtc = DecisionTreeClassifier()
rfe_dtc = RFE(dtc, n_features_to_select=5)
fit_dtc = rfe_dtc.fit(X_f, y_f)
pipeline_dtc = Pipeline(steps=[('s',rfe_dtc),('m',dtc)])

# evaluate model
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
scores_dtc = cross_val_score(pipeline_dtc, X_f, y_f, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')

acc = {
    "Methods": ["Logistic Regression","Decision Tree Classifier"],
    "Accuracy": [scores_lr, mean(scores_dtc)],
    "Selected Attributes": [lr_features, fit_dtc.get_feature_names_out()]
}
pd.set_option('display.max_colwidth', None)
st.dataframe(pd.DataFrame(acc))

"""Data Frame 11: Performance comparision of feature selection models and their selected columns

Based on the result above, it can be noticed that the decision tree classifier outperformed logistic regression in predicting the states given the values _cases_new, cumul_partial, cumul_full, deaths_cum, cases_cum_. with 88% of accuracy. So, columns selected by the decision tree classifier are retained as the feature for model building and testing.

## Machine Learning Algorithm

### Clustering:
In order to have a better overview and to quantify the risk, we have applied the clustering method to find out and analyse different clusters from the dataset. The clustering algorithm used is the K-Means. 

K-Means Clustering is an unsupervised learning centroid-based algorithm which allows us to cluster the data into different groups and gives us a convenient way to discover the categories of groups in the unlabeled dataset on its own without the need for any training.

(i) Clustering states in Malaysia into low, medium and high risk
"""

dfc1 = dcv_state[['date', 'state', 'cases_new', 'deaths_new']]
print(dfc1.shape)
st.dataframe(dfc1.head())

"""Data Frame 12: Data frame with daily cases_new and daily deaths_new in each state"""

alt.data_transformers.disable_max_rows()
selection = alt.selection_multi(fields = ['state'], bind = 'legend')
scales = alt.selection_interval(bind = 'scales')

st.altair_chart(alt.Chart(dfc1).mark_circle(size = 40).encode(
   x = 'cases_new',
   y = 'deaths_new',
   color = "state",
   tooltip = ['state', 'cases_new', 'deaths_new'],
   opacity = alt.condition(selection, alt.value(1), alt.value(0.05))
).properties(
   height = 350, width = 750
).add_selection(
   selection,
   scales
).interactive())

"""Figure 12: Scatter plot with daily new cases and new deaths counts for each state"""

X = dfc1.drop('date', axis=1)
X = pd.get_dummies(X)

km = KMeans(n_clusters = 3, random_state = 1)
km.fit(X)

dfkm = dfc1.copy()
dfkm = dfkm.drop("state", axis=1)
dfkm['Risk'] = km.labels_
dfkm['Risk'] = dfkm['Risk'].astype(str)

alt.data_transformers.disable_max_rows()
selection = alt.selection_multi(fields = ['Risk'], bind = 'legend')
scales = alt.selection_interval(bind = 'scales')
dom = ['0', '1', '2']
rng = ['#97d494', '#6baed6', '#e13128']

st.altair_chart(alt.Chart(dfkm).mark_circle(size = 40).encode(
   x = 'cases_new',
   y = 'deaths_new',
   color = alt.Color('Risk', scale = alt.Scale(domain = dom, range = rng)),
   tooltip = 'Risk',
   opacity = alt.condition(selection, alt.value(1), alt.value(0.05))
).properties(
   height = 350, width = 700
).add_selection(
   selection,
   scales
).interactive())

"""Figure 13: Scatter plot with three clusters that show the states in Malaysia in low, medium and high risk
As we can see in figure 13 above after clustering, the three colors of the data points indicate three different clusters. We describe the groupings as follows: Cluster 0 (green data points) - States in low risk, Cluster 1 (blue data points) - States in medium risk and Cluster 2 (red data points) - States in high risk.

Hence, by comparing and matching the two plots (Figure 12 & Figure 13), we can know and say that *Selangor* and *Sarawak* are **high** risk states, *Johor*, *Kedah*, *Kelantan*, *W.P. Kuala Lumpur*, *Sabah*, *Pulau Pinang*, *Negeri Sembilan* and *Perak* are considered as **medium** risk states while *Melaka*, *Pahang*, *Perlis*, *Terengganu*, *W.P. Putrajaya* and *W.P. Labuan* fall under **low** risk states.


(ii) Clustering states in Malaysia into low, medium and high vaccination rate.
"""

dfc2 = dcv_state[['date', 'state', 'daily']]
print(dfc2.shape)
st.dataframe(dfc2.head())

"""Data Frame 13: Data frame with daily vaccination count in each state."""

alt.data_transformers.disable_max_rows()
selection = alt.selection_multi(fields = ['state'], bind = 'legend')
scales = alt.selection_interval(bind = 'scales')

st.altair_chart(alt.Chart(dfc2).mark_circle(size = 40).encode(
   x = 'date:T',
   y = 'daily:Q',
   color = "state",
   tooltip = ['state', 'date:T', 'daily:Q'],
   opacity = alt.condition(selection, alt.value(1), alt.value(0.05))
).properties(
   height = 400, width = 750
).add_selection(
   selection,
   scales
).interactive())

"""Figure 14: Scatter plot with daily vaccination counts for each state."""

X = dfc2.drop('date', axis=1)
X = pd.get_dummies(X)

km = KMeans(n_clusters = 3, random_state = 1)
km.fit(X)

dfkm2 = dfc2.copy()
dfkm2 = dfkm2.drop("state", axis=1)
dfkm2['Rate'] = km.labels_
dfkm2['Rate'] = dfkm2['Rate'].astype(str)

alt.data_transformers.disable_max_rows()
selection = alt.selection_multi(fields = ['Rate'], bind = 'legend')
scales = alt.selection_interval(bind = 'scales')
dom = ['0', '1', '2']
rng = ['#e13128', '#6baed6', '#97d494']

st.altair_chart(alt.Chart(dfkm2).mark_circle(size = 40).encode(
   x = 'date:T',
   y = 'daily:Q',
   color = alt.Color('Rate', scale = alt.Scale(domain = dom, range = rng)),
   tooltip = 'Rate',
   opacity = alt.condition(selection, alt.value(1), alt.value(0.05))
).properties(
   height = 400, width = 700
).add_selection(
   selection,
   scales
).interactive())

"""Figure 15: Scatter plot with three clusters that show the states in Malaysia with low, medium and high vaccination rates.

As we can see in figure 15 above after clustering, there are also three different clusters indicated by the data points in three different colors and they can be described as follows: Cluster 0 (red data points) - States with low vaccination rate, Cluster 1 (blue data points) - States with medium vaccination rate and Cluster 2 (green data points) - States with high vaccination rate.

Thus, by comparing and matching the two plots (Figure 14 & Figure 15), *Selangor*, *Sarawak*, *Johor*, and *W.P. Kuala Lumpur* have **high** vaccination rates, *Kedah*, *Kelantan*, *Pahang*, *Perak*, *Pulau Pinang*, *Sabah*, *Terengganu*, and *Negeri Sembilan* are states with **medium** vaccination rates while *Perlis*, *W.P. Labuan*, *W.P. Putrajaya*, and *Melaka* are considered as states with **low** vaccination rates.


### Classification

Extended from the feature selection, a model is trained and built to predict the state when given _cases_new, cumul_partial, cumul_full, deaths_cum, cases_cum._ Two classification models applied are Decision Tree and Random Forest classifier.

Decision tree classification:
A decision tree is a type of machine learning model that is used when the relationship between a set of predictor variables and a response variable is non-linear.
Except for _random_state=1_, other parameters are set with the default option from [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)
"""

# Splitting dataset into training and testing sets
X_class = X_f.drop(X_f.columns.difference(['cases_new','cumul_partial','cumul_full','deaths_cum','cases_cum']), axis=1)
X_train, X_test, y_train, y_test = train_test_split(X_class, y_f, test_size=0.2, random_state=1)
actual = pd.DataFrame(y_test.value_counts()).sort_index().rename(columns={'state':'Count'})
actual['Type'] = "Actual"

# Decision tree 
dcs_clf = DecisionTreeClassifier(random_state=1)
dcs_clf = dcs_clf.fit(X_train, y_train)
pred_dcs = dcs_clf.predict(X_test)

# Model evaluation
dcs_acc = metrics.accuracy_score(y_test, pred_dcs)
dcs_pcs = metrics.precision_score(y_test, pred_dcs, average="macro")
dcs_rcl = metrics.recall_score(y_test, pred_dcs, average="macro")
performance = {
    "Accuracy" : [dcs_acc],
    "Precision" : [dcs_pcs],
    "Recall" : [dcs_rcl]
}
st.dataframe(pd.DataFrame(performance, index=["Decision Tree Classifier"]))

"""Data Frame 14: Performace of Decision Tree Classifier"""

# Decision tree outcome
pred_dt = pd.DataFrame(pd.Series(pred_dcs).value_counts(), columns=['Count']).sort_index()
pred_dt['Type'] = "Pred Decision Tree"
main_dt = pd.concat([actual, pred_dt]).sort_index().reset_index().rename(columns={'index':'States'})
st.dataframe(main_dt.head())

"""Data Frame 15: Comparison of predicted and actual labels of Decision Tree"""

# Bar chart for Decision Tree
st.altair_chart(alt.Chart(main_dt).mark_bar().encode(
    x='States:O',
    y='Count:Q',
    column='Type',
    color='States:N'
).properties(width=300,height=350).interactive())

"""Figure 16: Bar chart of actual and predicted counts of Decision Tree

Random forest classification:
An extension of the decision tree is a model known as a random forest, which is essentially a collection of decision trees.
Except for _random_state=1_, other parametres are set with the default option from [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)
"""

# Random forest
rdf_clf = RandomForestClassifier(random_state=1)
rdf_clf = rdf_clf.fit(X_train, y_train)
pred_rdf = rdf_clf.predict(X_test)

rdf_acc = metrics.accuracy_score(y_test, pred_rdf)
rdf_pcs = metrics.precision_score(y_test, pred_rdf, average="macro")
rdf_rcl = metrics.recall_score(y_test, pred_rdf, average="macro")
performance = {
    "Accuracy" : [rdf_acc],
    "Precision" : [rdf_pcs],
    "Recall" : [rdf_rcl]
}
st.dataframe(pd.DataFrame(performance, index=["Random Forest Classifier"]))

"""Data Frame 16: Performance of Random Forest Classifier"""

# Random forest outcome
pred_rf = pd.DataFrame(pd.Series(pred_rdf).value_counts(), columns=['Count']).sort_index()
pred_rf['Type'] = "Pred Random Forest"
main_rf = pd.concat([actual, pred_rf]).sort_index().reset_index().rename(columns={'index':'States'})
st.dataframe(main_rf.head())

"""Data Frame 17: Comparison of predicted and actual labels of Random Forest"""

# Bar chart for Random Forest
st.altair_chart(alt.Chart(main_rf).mark_bar().encode(
    x='States:O',
    y='Count:Q',
    column='Type',
    color='States:N'
).properties(width=300,height=350).interactive())

"""Figure 17: Bar chart of actual and predicted counts of Random Forest

Both models perform well in predicting states where given _cases_new, cumul_partial, cumul_full, deaths_cum, cases_cum_. However, the random forest classifier has a slightly higher performance of 9~10% than the decision tree classifier. The possible reason for this performance is because random forests have the advantage of doing better on unknown data than decision trees and are less prone to outliers by computing multiple decision trees.
In conclusion, the random forest classifier can be used to predict a state at risk if given high values of cases and deaths.

### Regression:
(i) Can Malaysia reach herd immunity on 30/11/2021?

LSTM have been used to predict the number of vaccination from 23/10/2021 - 30/11/2021 to predict if Malaysia current vaccination rate allow it to reach herd immunity by 30/11/2021. LSTM is used in this cased because LSTM is good for time series prediction using previous data. In our model, we use the past 60 days vaccination data to predict the next day vaccination number.
"""
# st.info("Note: The LSTM model takes around 3 minutes to train.")

# vac_train = vax_malaysia[vax_malaysia['date'] < "2021-08-24"]
# vac_test = vax_malaysia[vax_malaysia['date']>= "2021-08-24"]

# training_set = vac_train.iloc[:, 8: 9].values

# sc = MinMaxScaler(feature_range = (0, 1))
# training_set_scaled = sc.fit_transform(training_set)

# X_train = []
# y_train = []

# for i in range(60, len(training_set_scaled)):
#     X_train.append(training_set_scaled[i-60: i, 0])
#     y_train.append(training_set_scaled[i, 0])

# X_train, y_train = np.array(X_train), np.array(y_train)

# X_train = np.reshape(X_train, newshape = (X_train.shape[0], X_train.shape[1], 1))


# regressor = Sequential()

# regressor.add(LSTM(units = 200, return_sequences = True, input_shape = (X_train.shape[1], 1)))
# regressor.add(Dropout(rate = 0.2))

# regressor.add(LSTM(units = 200, return_sequences = True))
# regressor.add(Dropout(rate = 0.2))

# regressor.add(LSTM(units = 200, return_sequences = True))
# regressor.add(Dropout(rate = 0.2))

# regressor.add(LSTM(units = 200, return_sequences = False))
# regressor.add(Dropout(rate = 0.2))

# regressor.add(Dense(1))

# regressor.summary()

# regressor.compile(loss='mean_squared_error', optimizer='adam')
# regressor.fit(X_train, y_train, epochs = 100,batch_size=32)

# real_vac_count = vac_test.iloc[:, 8: 9].values
# dataset_total = pd.concat((vac_train['cumul_full'], vac_test['cumul_full']), axis = 0)

# inputs = dataset_total[len(dataset_total) - len(vac_test) - 60:].values
# #reshape data to only have 1 col
# inputs = inputs.reshape(-1, 1)

# #scale input
# inputs = sc.transform(inputs)

# X_test = []
# y_test = []
# for i in range(60, len(inputs)):
#     X_test.append(inputs[i-60: i, 0])
#     y_test.append(inputs[i, 0])

# X_test, y_test = np.array(X_test), np.array(y_test)

# X_test = np.reshape(X_test, newshape = (X_test.shape[0], X_test.shape[1], 1))
# predicted_vac_count = regressor.predict(X_test)

# predicted_vac_count = sc.inverse_transform(predicted_vac_count)

# plt.plot(real_vac_count, color = 'red', label = 'Real Vaccination Number')
# plt.plot(predicted_vac_count, color = 'blue', label = 'Predicted Vaccination Number')
# fig18 = plt.plot()
# plt.title('Vaccination Number Prediction')
# plt.xlabel('Time')
# plt.ylabel('Vaccination Number')
# plt.legend()
# plt.show()
# st.pyplot(fig18)
st.image("./picture/18.png")
"""Figure 18: Real Vaccination Number vs Predicted Vaccnination Number(24/8/2021 - 22/10/2021)

Figure 18 above shows the real vaccination number from 24/8/2021 - 22/10/2021. The red line indicates the real vaccination number and the blue line is the predicted value of vaccination number by our model. Our model have been tweaked a few times to reach this accuracy. 
"""

# dataset_predict = pd.DataFrame(vac_test['cumul_full'][-60:])
# X_predict = []
# y_predict= []

# inputs_predict = dataset_predict.values
# inputs_predict = inputs_predict.reshape(-1, 1)
# inputs_predict = sc.transform(inputs_predict)

# for i in range(39):
#     X_predict.append(inputs_predict[i: len(inputs_predict)+i, 0])
#     X_predict = np.array(X_predict)
#     X_predict = np.reshape(X_predict, newshape = (1, 60, 1))
#     nov_vac_count = regressor.predict(X_predict)
#     inputs_predict = np.append(inputs_predict, nov_vac_count)
#     inputs_predict = inputs_predict.reshape(-1, 1)
#     X_predict = []
    
# inputs_predict = sc.inverse_transform(inputs_predict)

# fig19a = plt.plot(inputs_predict, color = 'green', label = 'November Vaccination Number')
# fig19b = plt.plot(real_vac_count, color = 'red', label = 'Real Vaccination Number')
# fig19c = plt.plot(predicted_vac_count, color = 'blue', label = 'Predicted Vaccination Number')

# plt.title('Vaccination Number Prediction')
# plt.xlabel('Time')
# plt.ylabel('Vaccination Number')
# plt.legend()
# plt.show()
# st.pyplot()
st.image("./picture/19.png")

"""Figure 19: Predicting on November Vaccination Number 

The Figure 19 above shows the predicted November vaccination number based on our model. The green line indicates the predicted number on vaccination from 23/10/2021 - 30/11/2021.

(ii) Using regression to predict number of daily cases
"""

df2.tail(5)
X = df2[['daily_partial','daily_full','daily','daily_partial_child','daily_booster','cumul_partial','cumul_full','cumul','cumul_partial_child','cumul_full_child']]
y = df2['cases_new']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)

mlr = LinearRegression().fit(X_train, y_train)
dt= DecisionTreeRegressor(max_depth=5).fit(X_train,y_train)

mlr_pred = mlr.predict(X_test)
dt_pred = dt.predict(X_test)

mlr_reg_mse = metrics.mean_squared_error(y_test, mlr_pred)
mlr_reg_mae = metrics.mean_absolute_error(y_test, mlr_pred)
mlr_reg_r2 = metrics.r2_score(y_test, mlr_pred)

dt_reg_mse = metrics.mean_squared_error(y_test, dt_pred)
dt_reg_mae = metrics.mean_absolute_error(y_test, dt_pred)
dt_reg_r2 = metrics.r2_score(y_test, dt_pred)


df_temp = pd.DataFrame(mlr_pred,columns=['MLR Predicted Cases'])
df_temp2 = pd.DataFrame(y_test.values,columns=['Real Cases'])
df_temp3 = pd.DataFrame(dt_pred,columns=['DT Predicted Cases'])
df_concat = pd.concat([df_temp2,df_temp, df_temp3],axis=1)

model_name = ['Multiple Linear Regression','Decision Tree Regression']
data = {"Mean squared error": [mlr_reg_mse, dt_reg_mse],
        "Mean absolute error": [mlr_reg_mae, dt_reg_mae],
        "R^2 score" :[mlr_reg_r2, dt_reg_r2]}

mlr_score = pd.DataFrame(data,index=model_name)
st.dataframe(mlr_score)

"""Data Frame 18: Performance score of our regression models"""

st.dataframe(df_concat.head(5))

"""Data Frame 19: Real cases vs Predicted Cases by our regression models"""

df_concat.plot(kind= 'line')
ax = plt.gca()
plt.legend(bbox_to_anchor=(1, 1), bbox_transform=ax.transAxes)
st.pyplot()

"""Figure 20: Real cases vs predicted cases by our regression models

Blue line shows the real number of cases, orange line shows the predicted number of cases by Multiple Linear Regression model and green line shows the predicted number of cases by Decision Tree Regression model.
"""
